{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import gensim.downloader as api\n",
    "from gensim.matutils import unitvec\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yutorse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/yutorse/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"reuters\")\n",
    "# nltk.download(\"punkt\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = get_ipython().run_line_magic('pwd', '')\n",
    "path = os.path.join(path, \"BBC News Summary/Summaries/\")\n",
    "directory_list = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "\n",
    "documents = []\n",
    "for directory in directory_list:\n",
    "    for filename in os.listdir(path + directory):\n",
    "        with open(path + directory + \"/\" + filename, \"r\") as f:\n",
    "            documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yutorse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def preprocess_word(word):\n",
    "    word = word.lower()\n",
    "    if word in [\"\",\",\",\".\"]:\n",
    "        return None\n",
    "    if word in stop_words:\n",
    "        return None\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return None\n",
    "    elif lemma in stop_words:\n",
    "        return None\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "def preprocess_document(document):\n",
    "    words = nltk.word_tokenize(document)\n",
    "    words = [preprocess_word(word) for word in words]\n",
    "    words = [word for word in words if word is not None]\n",
    "    return words\n",
    "\n",
    "def preprocess_documents(documents):\n",
    "    return [preprocess_document(document) for document in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc2vec(preprocessed_document) \u001b[39mfor\u001b[39;00m preprocessed_document \u001b[39min\u001b[39;00m preprocessed_documents]\n\u001b[1;32m      9\u001b[0m preprocessed_documents \u001b[39m=\u001b[39m preprocess_documents(documents)\n\u001b[0;32m---> 10\u001b[0m document_vectors \u001b[39m=\u001b[39m docs2vecs(preprocessed_documents)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(document_vectors))\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mdocs2vecs\u001b[0;34m(preprocessed_documents)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdocs2vecs\u001b[39m(preprocessed_documents):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc2vec(preprocessed_document) \u001b[39mfor\u001b[39;00m preprocessed_document \u001b[39min\u001b[39;00m preprocessed_documents]\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdocs2vecs\u001b[39m(preprocessed_documents):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc2vec(preprocessed_document) \u001b[39mfor\u001b[39;00m preprocessed_document \u001b[39min\u001b[39;00m preprocessed_documents]\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mdoc2vec\u001b[0;34m(preprocessed_document)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdoc2vec\u001b[39m(preprocessed_document):\n\u001b[1;32m      2\u001b[0m     document_vec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[0;32m----> 3\u001b[0m         [model\u001b[39m.\u001b[39mget_vector(word, norm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m preprocessed_document \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m model], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m unitvec(document_vec)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdoc2vec\u001b[39m(preprocessed_document):\n\u001b[1;32m      2\u001b[0m     document_vec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[0;32m----> 3\u001b[0m         [model\u001b[39m.\u001b[39;49mget_vector(word, norm\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m preprocessed_document \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m model], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m unitvec(document_vec)\n",
      "File \u001b[0;32m~/miniconda3/envs/Tue2/lib/python3.8/site-packages/gensim/models/keyedvectors.py:448\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    446\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(key)\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m norm:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_norms()\n\u001b[1;32m    449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors[index] \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms[index]\n\u001b[1;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/Tue2/lib/python3.8/site-packages/gensim/models/keyedvectors.py:708\u001b[0m, in \u001b[0;36mKeyedVectors.fill_norms\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39mEnsure per-vector norms are available.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    705\u001b[0m \n\u001b[1;32m    706\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m force:\n\u001b[0;32m--> 708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectors, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Tue2/lib/python3.8/site-packages/numpy/linalg/linalg.py:2557\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2555\u001b[0m     \u001b[39m# special case for speedup\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     s \u001b[39m=\u001b[39m (x\u001b[39m.\u001b[39mconj() \u001b[39m*\u001b[39m x)\u001b[39m.\u001b[39mreal\n\u001b[0;32m-> 2557\u001b[0m     \u001b[39mreturn\u001b[39;00m sqrt(add\u001b[39m.\u001b[39;49mreduce(s, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49mkeepdims))\n\u001b[1;32m   2558\u001b[0m \u001b[39m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m \u001b[39m# are valid for vectors\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mord\u001b[39m, \u001b[39mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def doc2vec(preprocessed_document):\n",
    "    document_vec = np.mean(\n",
    "        [model.get_vector(word, norm=True) for word in preprocessed_document if word in model], axis=0)\n",
    "    return unitvec(document_vec)\n",
    "\n",
    "def docs2vecs(preprocessed_documents):\n",
    "    return [doc2vec(preprocessed_document) for preprocessed_document in preprocessed_documents]\n",
    "\n",
    "preprocessed_documents = preprocess_documents(documents)\n",
    "document_vectors = docs2vecs(preprocessed_documents)\n",
    "print(len(document_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeansClusterer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_clusters \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m kmeans \u001b[39m=\u001b[39m KMeansClusterer(n_clusters, cosine_distance, avoid_empty_clusters\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, repeats\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m clusters \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mcluster(docs2vecs(preprocessed_documents), assign_clusters\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KMeansClusterer' is not defined"
     ]
    }
   ],
   "source": [
    "n_clusters = 5\n",
    "kmeans = KMeansClusterer(n_clusters, cosine_distance, avoid_empty_clusters=True, repeats=10)\n",
    "clusters = kmeans.cluster(docs2vecs(preprocessed_documents), assign_clusters=True)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
